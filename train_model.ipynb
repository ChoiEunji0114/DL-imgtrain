{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy2Luh7WMqAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ReLU, BatchNormalization, Dropout, SeparableConv2D\n",
        "from tensorflow.keras import optimizers\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "from six.moves import cPickle\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# hyper parameter\n",
        "batch_size = 32\n",
        "num_classes = 100\n",
        "epochs = 40\n",
        "\n",
        "# 데이터 총 개수 : 40000개\n",
        "# 클래스 개수 : 100개, 클래스 별 400개 이미지\n",
        "\n",
        "steps_per_epoch = int(40000/batch_size)\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'trained_model.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAtrk71aU2ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.model_selection as sk\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "# train_data 가져오기 \n",
        "def load_data():\n",
        "    path = './'\n",
        "\n",
        "    fpath = os.path.join(path, 'train_data')\n",
        "    \n",
        "    with open(fpath, 'rb') as f:\n",
        "        d = cPickle.load(f, encoding='bytes')\n",
        "        \n",
        "    X_train = d['data']\n",
        "    y_train = d['labels']\n",
        "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
        "\n",
        "    return X_train, y_train\n",
        "\n",
        "x_train, y_train = load_data()\n",
        "\n",
        "\n",
        "# test, train dataset 분류하기 \n",
        "# validation accuracy를 확인하기 위해 train과 test데이터로 나누었다.\n",
        "X_train, X_test, y_train, y_test = sk.train_test_split(x_train,\n",
        "                                                    y_train,\n",
        "                                                    test_size=0.33,\n",
        "                                                    random_state=42,\n",
        "                                                    shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkXogH4ae_Jm",
        "colab_type": "code",
        "outputId": "5b927932-dc3b-401f-f5b1-e88564bb7dae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# normalize image data\n",
        "# 이미지 데이터 전처리\n",
        "\n",
        "# 데이터 학습이 잘 일어나도록 데이터들을 center에 맞춰주었다.\n",
        "# 차이를 확실히 보이기 위해 전처리 전과 후 평균과 분산 값을 출력해보았다.\n",
        "\n",
        "print (\"mean before normalization:\", np.mean(X_train)) \n",
        "print (\"std before normalization:\", np.std(X_train))\n",
        "\n",
        "mean=[0,0,0]\n",
        "std=[0,0,0]\n",
        "\n",
        "newX_train = np.ones(X_train.shape)\n",
        "newX_test = np.ones(X_test.shape)\n",
        "\n",
        "for i in range(3):\n",
        "    mean[i] = np.mean(X_train[:,:,:,i])\n",
        "    std[i] = np.std(X_train[:,:,:,i])\n",
        "       \n",
        "for i in range(3):\n",
        "    newX_train[:,:,:,i] = X_train[:,:,:,i] - mean[i]\n",
        "    newX_train[:,:,:,i] = newX_train[:,:,:,i] / std[i]\n",
        "    newX_test[:,:,:,i] = X_test[:,:,:,i] - mean[i]\n",
        "    newX_test[:,:,:,i] = newX_test[:,:,:,i] / std[i]\n",
        "\n",
        "X_train = newX_train\n",
        "X_test = newX_test\n",
        "\n",
        "print (\"mean after normalization:\", np.mean(X_train))\n",
        "print (\"std after normalization:\", np.std(X_train))\n",
        "print(X_train.max())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean before normalization: 121.98364992663635\n",
            "std before normalization: 68.30227829343998\n",
            "mean after normalization: 5.568237965794131e-17\n",
            "std after normalization: 0.9999999999999987\n",
            "2.025461104398623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBxGgzX6fIpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# label preprocessing\n",
        "# 클래스 벡터(정수들)를 바이너리 클래스 매트릭스로 변환한다.\n",
        "# 보통 'categorical_crossentropy' 와 같이 쓰인다.\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDxkko6XfQ3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make dataset\n",
        "# 이미지 데이터와 라벨 데이터로 dataset을 생성했다.\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "dataset = dataset.batch(32)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "val_dataset = val_dataset.batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY1zaFaio3SW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "callbacks = [\n",
        "  tf.keras.callbacks.EarlyStopping(patience=4, monitor='val_loss')\n",
        "]\n",
        "\n",
        "# callbacks 함수 추가\n",
        "# 의미없이 epoch 을 돌지 않도록 val_loss 값이 4번 연속 상승하면 자동으로 학습을 중지하도록 했다.\n",
        "\n",
        "def scheduler(epoch):\n",
        "  if epoch < 10:\n",
        "    return 0.001\n",
        "  else:\n",
        "    return 0.001 * tf.math.exp(0.1 * (10 - epoch))\n",
        "\n",
        "# scheduler 함수 추가 \n",
        "# 각 epoch 마다 learning rate 을 조절한다. \n",
        "# epoch 10 미만이면 0.001이고 10부터 rate 값이 소폭 감소하기 시작한다. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwgVfua1Uil5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "from keras.optimizers import adam\n",
        "\n",
        "\n",
        "# create model \n",
        "\n",
        "# 효과적으로 학습을 위해 각 layer에 다음과 같은 방법을 사용했다. \n",
        "\n",
        "# 1. kernel_initializer = 'he_uniform' \n",
        "# 초기값 설정은 'he_uniform' 방법을 사용했다.\n",
        "\n",
        "# 2. kernel_regularizer=12(0.001), bias_regularizerr=l2(0.001)\n",
        "# weight regularization 으로 l2를 사용했다.\n",
        "# l2는 l1과 다르게 가중치를 완전히 0으로 만들지는 않기 때문에 l1보다 효과적이다.\n",
        "# rate 값으로 0.001을 사용했다. 다른 값들보다 0.001이 가장 학습이 잘 일어난다.\n",
        "\n",
        "# 3. activation = 'relu'\n",
        "# 활성화 함수로 relu를 사용했다. \n",
        "\n",
        "# 4. Add BatchNormalization\n",
        "# 학습 성능을 높여주기 위해 layer마다 배치 정규화를 시켜주었다. \n",
        "\n",
        "# 5. Add Dropout \n",
        "# overfit을 방지하기 위해 특정 노드를 제거하는 dropout을 추가했다.\n",
        "# 각 layer마다 0.25 dropout을 지정해주었고, 마지막 레이어에는 0.5 dropout을 지정했다.\n",
        "\n",
        "# 6. adam = optimizers.Adam(lr = 0.001, decay=1e-5)\n",
        "# optimize방법으로 가장 효과가 좋은 adam으로 설정했다. \n",
        "# learning rate 는 0.001, decay값으로 1e-5으로 설정했다.  \n",
        "\n",
        "# 7. Add Layer\n",
        "# 기존 모델에서 총 4개의 layer를 추가했다. \n",
        "\n",
        "\n",
        "def create_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  # layer1\n",
        "  model.add(Conv2D(64, (3, 3), \n",
        "                    padding='same',\n",
        "                    input_shape=X_train.shape[1:],\n",
        "                    kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=l2(0.001),\n",
        "                    bias_regularizer=l2(0.001),\n",
        "                    activation='relu'\n",
        "                    ))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # layer2\n",
        "  model.add(Conv2D(64, (3, 3), \n",
        "                    padding='same',\n",
        "                    kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=l2(0.001),\n",
        "                    bias_regularizer=l2(0.001),\n",
        "                    activation='relu'\n",
        "                    ))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # layer3\n",
        "  model.add(Conv2D(128, (3, 3), \n",
        "                    kernel_initializer='he_uniform',\n",
        "                    activation='relu',\n",
        "                    kernel_regularizer=l2(0.001),\n",
        "                    bias_regularizer=l2(0.001),\n",
        "                    padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # layer4\n",
        "  model.add(Conv2D(256, (3, 3),\n",
        "                    kernel_initializer='he_uniform', \n",
        "                    activation='relu',\n",
        "                    kernel_regularizer=l2(0.001),\n",
        "                    bias_regularizer=l2(0.001),\n",
        "                    padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  \n",
        "  # layer5\n",
        "  model.add(Conv2D(512, (3, 3), \n",
        "                    kernel_initializer='he_uniform',\n",
        "                    activation='relu',\n",
        "                    kernel_regularizer=l2(0.001),\n",
        "                    bias_regularizer=l2(0.001),\n",
        "                    padding='same'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "\n",
        "  model.add(Dense(512, \n",
        "                  kernel_initializer='he_uniform'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(num_classes,\n",
        "                  kernel_initializer='he_uniform',\n",
        "                  kernel_regularizer=l2(0.001),\n",
        "                  bias_regularizer=l2(0.001),\n",
        "                  activation='softmax'))\n",
        "\n",
        "  adam = optimizers.Adam(lr = 0.001, decay=1e-5)\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=adam,\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MQS1mqdtc5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b027dccc-8af2-41ff-b94d-512451874025"
      },
      "source": [
        "# 학습 모델 만들기 \n",
        "model = create_model()\n",
        "\n",
        "# 이미지 학습 시키기 \n",
        "history = model.fit(dataset, \n",
        "           epochs=epochs,\n",
        "           shuffle=True,\n",
        "           validation_data=val_dataset,\n",
        "           callbacks=[LearningRateScheduler(scheduler, verbose=1), callbacks],\n",
        "           workers=4)\n",
        "\n",
        "# 이미지 학습 옵션 추가\n",
        "# 1. shuffle = True \n",
        "# 랜덤하게 데이터 학습하기 위해 추가한 옵션이다.\n",
        "# 2. callbacks=[LearningRateScheduler(scheduler, verbose=1), callbacks]\n",
        "# 아까 만든 콜백 함수들을 모델 학습시킬 때 적용했다.\n",
        "\n",
        "# 정확도 찍어보기 \n",
        "results = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy: ', results[1])\n",
        "\n",
        "\n",
        "# 학습 결과\n",
        "# accuracy: 0.9234 - val_loss: 2.7191 - val_accuracy: 0.5702 - lr: 5.5023e-05\n",
        "# Test accuracy:  0.5701515078544617\n",
        "\n",
        "# accuracy 값은 높이 나오지만 val_accuracy값과 차이가 나는 overfitting 현상을 보이고 있다.\n",
        "# 그러나 epoch 돌 때마다  val_accuracy 값이 소폭으로 증가하고 있다. \n",
        "# val_loss 값 역시 epoch 돌 때마다 소폭으로 감소하고 있다. "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 1/40\n",
            "838/838 [==============================] - 12s 14ms/step - loss: 11.8055 - accuracy: 0.0525 - val_loss: 13.4252 - val_accuracy: 0.0893 - lr: 0.0010\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 2/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 7.4116 - accuracy: 0.1113 - val_loss: 5.7220 - val_accuracy: 0.1914 - lr: 0.0010\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 3/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 5.3966 - accuracy: 0.1844 - val_loss: 4.8712 - val_accuracy: 0.2628 - lr: 0.0010\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 4/40\n",
            "838/838 [==============================] - 13s 16ms/step - loss: 4.4530 - accuracy: 0.2556 - val_loss: 4.2304 - val_accuracy: 0.3155 - lr: 0.0010\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 5/40\n",
            "838/838 [==============================] - 13s 16ms/step - loss: 3.9960 - accuracy: 0.3032 - val_loss: 3.7705 - val_accuracy: 0.3416 - lr: 0.0010\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 6/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 3.7959 - accuracy: 0.3366 - val_loss: 3.7131 - val_accuracy: 0.3559 - lr: 0.0010\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 7/40\n",
            "838/838 [==============================] - 12s 15ms/step - loss: 3.7296 - accuracy: 0.3609 - val_loss: 3.6259 - val_accuracy: 0.3923 - lr: 0.0010\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 8/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 3.6847 - accuracy: 0.3821 - val_loss: 3.5660 - val_accuracy: 0.4082 - lr: 0.0010\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 9/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 3.6340 - accuracy: 0.3989 - val_loss: 3.5569 - val_accuracy: 0.4268 - lr: 0.0010\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 10/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 3.5867 - accuracy: 0.4171 - val_loss: 3.5703 - val_accuracy: 0.4290 - lr: 0.0010\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to tf.Tensor(0.001, shape=(), dtype=float32).\n",
            "Epoch 11/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 3.5375 - accuracy: 0.4330 - val_loss: 3.5243 - val_accuracy: 0.4463 - lr: 0.0010\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to tf.Tensor(0.0009048374, shape=(), dtype=float32).\n",
            "Epoch 12/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 3.4042 - accuracy: 0.4645 - val_loss: 3.4146 - val_accuracy: 0.4595 - lr: 9.0484e-04\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to tf.Tensor(0.0008187308, shape=(), dtype=float32).\n",
            "Epoch 13/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 3.2399 - accuracy: 0.4888 - val_loss: 3.2945 - val_accuracy: 0.4823 - lr: 8.1873e-04\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to tf.Tensor(0.00074081816, shape=(), dtype=float32).\n",
            "Epoch 14/40\n",
            "838/838 [==============================] - 12s 14ms/step - loss: 3.0808 - accuracy: 0.5179 - val_loss: 3.2179 - val_accuracy: 0.4910 - lr: 7.4082e-04\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to tf.Tensor(0.00067032006, shape=(), dtype=float32).\n",
            "Epoch 15/40\n",
            "838/838 [==============================] - 11s 13ms/step - loss: 2.9442 - accuracy: 0.5433 - val_loss: 3.1569 - val_accuracy: 0.5043 - lr: 6.7032e-04\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to tf.Tensor(0.0006065307, shape=(), dtype=float32).\n",
            "Epoch 16/40\n",
            "838/838 [==============================] - 12s 15ms/step - loss: 2.7840 - accuracy: 0.5726 - val_loss: 3.1133 - val_accuracy: 0.5077 - lr: 6.0653e-04\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to tf.Tensor(0.00054881163, shape=(), dtype=float32).\n",
            "Epoch 17/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 2.6583 - accuracy: 0.6001 - val_loss: 3.0442 - val_accuracy: 0.5203 - lr: 5.4881e-04\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to tf.Tensor(0.00049658533, shape=(), dtype=float32).\n",
            "Epoch 18/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 2.5223 - accuracy: 0.6264 - val_loss: 3.0389 - val_accuracy: 0.5251 - lr: 4.9659e-04\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to tf.Tensor(0.00044932897, shape=(), dtype=float32).\n",
            "Epoch 19/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 2.3757 - accuracy: 0.6566 - val_loss: 2.9944 - val_accuracy: 0.5259 - lr: 4.4933e-04\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to tf.Tensor(0.0004065697, shape=(), dtype=float32).\n",
            "Epoch 20/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 2.2520 - accuracy: 0.6828 - val_loss: 2.9886 - val_accuracy: 0.5314 - lr: 4.0657e-04\n",
            "\n",
            "Epoch 00021: LearningRateScheduler reducing learning rate to tf.Tensor(0.00036787946, shape=(), dtype=float32).\n",
            "Epoch 21/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 2.1216 - accuracy: 0.7097 - val_loss: 2.9599 - val_accuracy: 0.5361 - lr: 3.6788e-04\n",
            "\n",
            "Epoch 00022: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003328711, shape=(), dtype=float32).\n",
            "Epoch 22/40\n",
            "838/838 [==============================] - 12s 14ms/step - loss: 2.0010 - accuracy: 0.7344 - val_loss: 2.9208 - val_accuracy: 0.5456 - lr: 3.3287e-04\n",
            "\n",
            "Epoch 00023: LearningRateScheduler reducing learning rate to tf.Tensor(0.0003011942, shape=(), dtype=float32).\n",
            "Epoch 23/40\n",
            "838/838 [==============================] - 12s 14ms/step - loss: 1.9009 - accuracy: 0.7540 - val_loss: 2.9089 - val_accuracy: 0.5482 - lr: 3.0119e-04\n",
            "\n",
            "Epoch 00024: LearningRateScheduler reducing learning rate to tf.Tensor(0.00027253182, shape=(), dtype=float32).\n",
            "Epoch 24/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 1.8015 - accuracy: 0.7737 - val_loss: 2.9203 - val_accuracy: 0.5442 - lr: 2.7253e-04\n",
            "\n",
            "Epoch 00025: LearningRateScheduler reducing learning rate to tf.Tensor(0.000246597, shape=(), dtype=float32).\n",
            "Epoch 25/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 1.7062 - accuracy: 0.7948 - val_loss: 2.8933 - val_accuracy: 0.5498 - lr: 2.4660e-04\n",
            "\n",
            "Epoch 00026: LearningRateScheduler reducing learning rate to tf.Tensor(0.00022313018, shape=(), dtype=float32).\n",
            "Epoch 26/40\n",
            "838/838 [==============================] - 12s 15ms/step - loss: 1.6336 - accuracy: 0.8107 - val_loss: 2.8468 - val_accuracy: 0.5592 - lr: 2.2313e-04\n",
            "\n",
            "Epoch 00027: LearningRateScheduler reducing learning rate to tf.Tensor(0.00020189652, shape=(), dtype=float32).\n",
            "Epoch 27/40\n",
            "838/838 [==============================] - 12s 15ms/step - loss: 1.5468 - accuracy: 0.8275 - val_loss: 2.8471 - val_accuracy: 0.5587 - lr: 2.0190e-04\n",
            "\n",
            "Epoch 00028: LearningRateScheduler reducing learning rate to tf.Tensor(0.00018268352, shape=(), dtype=float32).\n",
            "Epoch 28/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 1.4802 - accuracy: 0.8399 - val_loss: 2.8458 - val_accuracy: 0.5540 - lr: 1.8268e-04\n",
            "\n",
            "Epoch 00029: LearningRateScheduler reducing learning rate to tf.Tensor(0.0001652989, shape=(), dtype=float32).\n",
            "Epoch 29/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 1.4198 - accuracy: 0.8512 - val_loss: 2.8235 - val_accuracy: 0.5601 - lr: 1.6530e-04\n",
            "\n",
            "Epoch 00030: LearningRateScheduler reducing learning rate to tf.Tensor(0.00014956863, shape=(), dtype=float32).\n",
            "Epoch 30/40\n",
            "838/838 [==============================] - 12s 15ms/step - loss: 1.3599 - accuracy: 0.8642 - val_loss: 2.8120 - val_accuracy: 0.5606 - lr: 1.4957e-04\n",
            "\n",
            "Epoch 00031: LearningRateScheduler reducing learning rate to tf.Tensor(0.00013533529, shape=(), dtype=float32).\n",
            "Epoch 31/40\n",
            "838/838 [==============================] - 11s 13ms/step - loss: 1.3050 - accuracy: 0.8731 - val_loss: 2.8050 - val_accuracy: 0.5643 - lr: 1.3534e-04\n",
            "\n",
            "Epoch 00032: LearningRateScheduler reducing learning rate to tf.Tensor(0.00012245645, shape=(), dtype=float32).\n",
            "Epoch 32/40\n",
            "838/838 [==============================] - 12s 14ms/step - loss: 1.2616 - accuracy: 0.8820 - val_loss: 2.7934 - val_accuracy: 0.5642 - lr: 1.2246e-04\n",
            "\n",
            "Epoch 00033: LearningRateScheduler reducing learning rate to tf.Tensor(0.00011080316, shape=(), dtype=float32).\n",
            "Epoch 33/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 1.2236 - accuracy: 0.8893 - val_loss: 2.7843 - val_accuracy: 0.5645 - lr: 1.1080e-04\n",
            "\n",
            "Epoch 00034: LearningRateScheduler reducing learning rate to tf.Tensor(0.000100258854, shape=(), dtype=float32).\n",
            "Epoch 34/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 1.1838 - accuracy: 0.8972 - val_loss: 2.7785 - val_accuracy: 0.5673 - lr: 1.0026e-04\n",
            "\n",
            "Epoch 00035: LearningRateScheduler reducing learning rate to tf.Tensor(9.071795e-05, shape=(), dtype=float32).\n",
            "Epoch 35/40\n",
            "838/838 [==============================] - 13s 15ms/step - loss: 1.1507 - accuracy: 0.9028 - val_loss: 2.7567 - val_accuracy: 0.5710 - lr: 9.0718e-05\n",
            "\n",
            "Epoch 00036: LearningRateScheduler reducing learning rate to tf.Tensor(8.2085e-05, shape=(), dtype=float32).\n",
            "Epoch 36/40\n",
            "838/838 [==============================] - 12s 14ms/step - loss: 1.1247 - accuracy: 0.9064 - val_loss: 2.7373 - val_accuracy: 0.5710 - lr: 8.2085e-05\n",
            "\n",
            "Epoch 00037: LearningRateScheduler reducing learning rate to tf.Tensor(7.427359e-05, shape=(), dtype=float32).\n",
            "Epoch 37/40\n",
            "838/838 [==============================] - 11s 14ms/step - loss: 1.0966 - accuracy: 0.9114 - val_loss: 2.7368 - val_accuracy: 0.5686 - lr: 7.4274e-05\n",
            "\n",
            "Epoch 00038: LearningRateScheduler reducing learning rate to tf.Tensor(6.720552e-05, shape=(), dtype=float32).\n",
            "Epoch 38/40\n",
            "838/838 [==============================] - 12s 14ms/step - loss: 1.0660 - accuracy: 0.9178 - val_loss: 2.7357 - val_accuracy: 0.5730 - lr: 6.7206e-05\n",
            "\n",
            "Epoch 00039: LearningRateScheduler reducing learning rate to tf.Tensor(6.0810067e-05, shape=(), dtype=float32).\n",
            "Epoch 39/40\n",
            "838/838 [==============================] - 12s 14ms/step - loss: 1.0470 - accuracy: 0.9204 - val_loss: 2.7277 - val_accuracy: 0.5703 - lr: 6.0810e-05\n",
            "\n",
            "Epoch 00040: LearningRateScheduler reducing learning rate to tf.Tensor(5.5023214e-05, shape=(), dtype=float32).\n",
            "Epoch 40/40\n",
            "838/838 [==============================] - 12s 15ms/step - loss: 1.0311 - accuracy: 0.9234 - val_loss: 2.7191 - val_accuracy: 0.5702 - lr: 5.5023e-05\n",
            "413/413 [==============================] - 2s 4ms/step - loss: 2.7191 - accuracy: 0.5702\n",
            "Test accuracy:  0.5701515078544617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnZami4Cl0_z",
        "colab_type": "code",
        "outputId": "29d3a1f2-1b1c-41c9-bc94-e96e79984595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# 결과를 한 눈에 확인하기 위해 plot에 그래프를 그려보았다. \n",
        "# train loss, val loss, train acc, val acc 를 그렸다.\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "\n",
        "acc_ax = loss_ax.twinx()\n",
        "\n",
        "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
        "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
        "\n",
        "acc_ax.plot(history.history['accuracy'], 'b', label='train acc')\n",
        "acc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')\n",
        "\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "acc_ax.set_ylabel('accuray')\n",
        "\n",
        "loss_ax.legend(loc='upper left')\n",
        "acc_ax.legend(loc='lower left')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# epoch 20 이후 부터는 val acc 값이 소폭으로 상승하기 시작한다.\n",
        "# val loss 값 역시 epoch 20부터 소폭으로 감소하기 시작한다. "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEOvrF0vkSKu",
        "colab_type": "code",
        "outputId": "aba5e01e-4a74-496f-ac79-beb49506ceed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# save model\n",
        "\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved trained model at /content/saved_models/trained_model.h5 \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}